"""
æµ‹è¯•ä¸åŒ LLM æ¨¡å‹çš„è§£ææ•ˆæœå’Œ token ä½¿ç”¨é‡
"""
import asyncio
import sys
import time
import json
from pathlib import Path
import httpx

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.report_parser_service import ReportParserService
from app.config import get_settings

settings = get_settings()

# æµ‹è¯•ç”¨ä¾‹
TEST_THIS_WEEK = """1. æ¸…æ˜ä¸Šæ²³å›­æ²Ÿé€šå¯¹æ¥
2. ä¸€çœä¸€æŠ¥ç³»ç»ŸåŠŸèƒ½ä¼˜åŒ–
3. å¤§æ²³äº‘AIå‡çº§éœ€æ±‚è®¨è®º
4. æœåŠ¡å™¨è¿ç»´å·¡æ£€
5. RAGçŸ¥è¯†åº“è°ƒç ”"""

TEST_NEXT_WEEK = """1. ç»§ç»­æ¸…æ˜ä¸Šæ²³å›­é¡¹ç›®å¼€å‘
2. å®Œæˆä¸€çœä¸€æŠ¥é€šé“ç®¡ç†åŠŸèƒ½
3. å‚åŠ AIå‡çº§æŠ€æœ¯è¯„å®¡"""


def estimate_tokens(text: str) -> int:
    """ä¼°ç®—ä¸­æ–‡æ–‡æœ¬çš„ token æ•°ï¼ˆç²—ç•¥ï¼š1ä¸ªä¸­æ–‡å­—â‰ˆ1.5 tokenï¼‰"""
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    other_chars = len(text) - chinese_chars
    return int(chinese_chars * 1.5 + other_chars * 0.3)


async def call_dashscope(prompt: str, system: str, model: str) -> tuple[str, dict]:
    """è°ƒç”¨ DashScope APIï¼Œè¿”å›å“åº”å’Œ usage ä¿¡æ¯"""
    url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {settings.DASHSCOPE_API_KEY}",
        "Content-Type": "application/json"
    }
    messages = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})

    payload = {
        "model": model,
        "messages": messages,
        "temperature": 0.3,
        "max_tokens": 2000
    }

    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(url, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        content = result["choices"][0]["message"]["content"]
        usage = result.get("usage", {})
        return content, usage


async def call_deepseek(prompt: str, system: str) -> tuple[str, dict]:
    """è°ƒç”¨ DeepSeek API"""
    url = f"{settings.DEEPSEEK_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {settings.DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    messages = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})

    payload = {
        "model": "deepseek-chat",
        "messages": messages,
        "temperature": 0.3,
        "max_tokens": 2000
    }

    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(url, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        content = result["choices"][0]["message"]["content"]
        usage = result.get("usage", {})
        return content, usage


async def test_model(model_name: str, provider: str):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•æ¨¡å‹: {model_name} (provider: {provider})")
    print('='*60)

    # åˆ›å»ºæœåŠ¡å®ä¾‹
    parser = ReportParserService()

    # è·å–é¡¹ç›®åˆ—è¡¨
    known_projects = parser._get_known_projects_str()

    # æ„å»ºå®Œæ•´ prompt
    full_prompt = parser.PARSE_PROMPT_TEMPLATE.format(
        known_projects=known_projects,
        this_week_work=TEST_THIS_WEEK,
        next_week_plan=TEST_NEXT_WEEK
    )
    system_prompt = parser.PARSE_SYSTEM_PROMPT

    # Token ä¼°ç®—
    estimated_input = estimate_tokens(system_prompt + full_prompt)
    print(f"\nğŸ“Š Prompt ä¿¡æ¯:")
    print(f"   System Prompt å­—ç¬¦æ•°: {len(system_prompt)}")
    print(f"   é¡¹ç›®åˆ—è¡¨å­—ç¬¦æ•°: {len(known_projects)}")
    print(f"   ç”¨æˆ·è¾“å…¥å­—ç¬¦æ•°: {len(TEST_THIS_WEEK + TEST_NEXT_WEEK)}")
    print(f"   æ€» Prompt å­—ç¬¦æ•°: {len(system_prompt + full_prompt)}")

    start_time = time.time()
    try:
        if provider == "dashscope":
            response, usage = await call_dashscope(full_prompt, system_prompt, model_name)
        else:
            response, usage = await call_deepseek(full_prompt, system_prompt)

        elapsed = time.time() - start_time

        # å®é™… token ä½¿ç”¨é‡
        input_tokens = usage.get("prompt_tokens", estimated_input)
        output_tokens = usage.get("completion_tokens", estimate_tokens(response))
        total_tokens = usage.get("total_tokens", input_tokens + output_tokens)

        print(f"\nğŸ“Š å®é™… Token ä½¿ç”¨é‡ (API è¿”å›):")
        print(f"   è¾“å…¥ tokens: {input_tokens}")
        print(f"   è¾“å‡º tokens: {output_tokens}")
        print(f"   æ€»è®¡ tokens: {total_tokens}")
        print(f"\nâ±ï¸  å“åº”æ—¶é—´: {elapsed:.2f}s")

        # è§£æç»“æœ
        print(f"\nğŸ“ åŸå§‹å“åº” (å‰500å­—ç¬¦):")
        print(response[:500] + "..." if len(response) > 500 else response)

        # å°è¯•è§£æ JSON
        parse_success = False
        try:
            cleaned = parser._clean_json_response(response)
            parsed = json.loads(cleaned)
            this_week_count = len(parsed.get("this_week_items", []))
            next_week_count = len(parsed.get("next_week_items", []))
            print(f"\nâœ… è§£ææˆåŠŸ: æœ¬å‘¨{this_week_count}æ¡, ä¸‹å‘¨{next_week_count}æ¡")
            parse_success = True

            # æ˜¾ç¤ºè§£æç»“æœ
            print("\næœ¬å‘¨å·¥ä½œè§£æ:")
            for item in parsed.get("this_week_items", []):
                proj = item.get("project_name") or "æœªåˆ†ç±»"
                content = item.get("content", "")[:40]
                print(f"   [{proj}] {content}")

        except json.JSONDecodeError as e:
            print(f"\nâŒ JSON è§£æå¤±è´¥: {e}")

    except Exception as e:
        print(f"\nâŒ è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

    return {
        "model": model_name,
        "provider": provider,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_tokens": total_tokens,
        "response_time": elapsed,
        "parse_success": parse_success
    }


async def main():
    print("="*60)
    print("LLM æ¨¡å‹æ•ˆæœä¸ Token ä½¿ç”¨é‡æµ‹è¯•")
    print("="*60)

    # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
    models = [
        ("qwen-turbo", "dashscope"),      # æœ€å¿«æœ€ä¾¿å®œ
        ("qwen-plus", "dashscope"),       # å¹³è¡¡
        ("deepseek-chat", "deepseek"),    # DeepSeek
    ]

    results = []
    for model_name, provider in models:
        result = await test_model(model_name, provider)
        if result:
            results.append(result)

    # æ±‡æ€»å¯¹æ¯”
    print("\n" + "="*60)
    print("ğŸ“Š æ¨¡å‹å¯¹æ¯”æ±‡æ€»")
    print("="*60)
    print(f"{'æ¨¡å‹':<20} {'å“åº”æ—¶é—´':>10} {'è¾“å…¥tokens':>12} {'è¾“å‡ºtokens':>12} {'æ€»tokens':>10}")
    print("-"*60)
    for r in results:
        print(f"{r['model']:<20} {r['response_time']:>8.2f}s {r['input_tokens']:>12} {r['output_tokens']:>12} {r['total_tokens']:>10}")

    # è´¹ç”¨ä¼°ç®—ï¼ˆæŒ‰é€šä¹‰åƒé—®å®šä»·ï¼‰
    print("\nğŸ’° è´¹ç”¨ä¼°ç®— (æ¯æ¬¡è§£æ):")
    print("   qwen-turbo:  è¾“å…¥ Â¥0.0003/1K + è¾“å‡º Â¥0.0006/1K")
    print("   qwen-plus:   è¾“å…¥ Â¥0.0008/1K + è¾“å‡º Â¥0.002/1K")
    print("   deepseek:    è¾“å…¥ Â¥0.001/1K  + è¾“å‡º Â¥0.002/1K")


if __name__ == "__main__":
    asyncio.run(main())
